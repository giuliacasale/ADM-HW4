{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import hyperloglog\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. HASHING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_len = 125000001 # obtained with set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Built-in HLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HLL(file,nlines):\n",
    "    f = open(file, \"r\")\n",
    "    hll = hyperloglog.HyperLogLog(0.01)  # accept 1% counting error\n",
    "    for n in range(1,nlines):\n",
    "        req = f.readline(n)\n",
    "        hll.add(req)\n",
    "    \n",
    "    return len(hll) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "card = HLL('hash.txt',139000000)\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 216.43159770965576  seconds\n",
      "Error obatined with the built-in hyperloglog is: 0.06426126807226587\n"
     ]
    }
   ],
   "source": [
    "print ('Execution time:',end-start, ' seconds')\n",
    "print('Error obatined with the built-in hyperloglog is:',((real_len-card)/card)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My_HLL\n",
    "1. For each request we compute the hash. We generate a random hash function that maps strings to a 32 bits vector. It will gives us a uniform distribution across the number of requests. \n",
    "\n",
    "3. The first m bits in this vector represents the bucket to which we should assign a certain request. If we have for example p = 10 we should consider the first 1024 bits since $2^{10} = 1024$, which is the total number of combination of the values [0,1] for 10 digits. Therefore the number of buckets will always be a power of 2.\n",
    "\n",
    "4. If we have a good and random hash function that acted on strings and generated binary vectors we would expect: $1/2^n$ of them to have their binary representation starting in $0*n$. Therefore we determine the number of leftmost zeros for each request. If the number of leftmost zeros for the $i*{th}$ element is *k* and it is higher than the max *k* generated so far, *k* is stored as the new max value for that bucket.\n",
    "\n",
    "5. Once input is exhausted, we call the cardinality function on all the buckets. We calculate the number of unique words with the following formula:\n",
    "\n",
    "    ${\\displaystyle E=\\alpha _{m}m^{2}Z}$ \\\n",
    "     \\\n",
    "    Where: \n",
    "    \n",
    "    $Z=\\sum _{j=1}^{m}{2^{-M[j]}}^{-1}$ and $\\alpha _{m} = 0.7213/(1+1.079/(2^{m}))$ \n",
    "    \n",
    " \n",
    "6. The observed error depends on the number of buckets m and it is given by the formula: \\\n",
    "    $ error=\\frac{1.04}{\\sqrt(2^p)}$ \\\n",
    "    where *p* is the exponent we give to 2 to obtain *m*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_fun(string,n):\n",
    "    m = 2**n\n",
    "    if len(string)!=0:\n",
    "        random.seed(20) \n",
    "        x,y,z=random.sample(range(1,m),3)\n",
    "        hashed_up=(int(string[:13],16)*x + int(string[13:26],16)*y + int(string[26:],16)*z) % m\n",
    "        l=len(bin(hashed_up)[2:])\n",
    "        return '0'*(n-l)+bin(hashed_up)[2:]\n",
    "    else:\n",
    "        return'0'*n\n",
    "\n",
    "def my_hll(file,p,n_lines):     \n",
    "    f = open(file, \"r\")\n",
    "    m = 2**p\n",
    "    buckets = [0]*m\n",
    "    for request in range(35,n_lines):\n",
    "        line = f.readline(request)\n",
    "        binary = hash_fun(line,32)\n",
    "        index = int(binary[:p],2) \n",
    "        end = binary[p:] \n",
    "        buckets[index]=max(buckets[index],leftmost_zeros(end))\n",
    "\n",
    "    card = cardinality(buckets,m)\n",
    "\n",
    "    return (card)\n",
    "\n",
    "def cardinality(buckets,m):\n",
    "    Z = 1/sum([2**(-bucket-1) for bucket in buckets])\n",
    "    alfa_m = 0.7213/(1+1.079/(m))\n",
    "    E = alfa_m*(m**2)*Z\n",
    "    return E\n",
    "\n",
    "def leftmost_zeros(b):\n",
    "    i = 0\n",
    "    while b[i] == '0' :\n",
    "        i+=1\n",
    "        if len(b[i:]) == 0:\n",
    "            break\n",
    "    return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "my_card = my_hll('hash.txt',12,139000000)\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Execution time is: 23.18  minutes\n",
      " The estimated cardinality is: 124212668\n",
      " Experimental error: 0.63 %\n"
     ]
    }
   ],
   "source": [
    "print(' Execution time is:',round((end-start)/60,2), ' minutes' )\n",
    "print(' The estimated cardinality is:', round(my_card,0))\n",
    "print(' Experimental error:',round((real_len-my_card)/(real_len)*100,3), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.Algorithmic question\n",
    "You are given an array with A with n integer numbers. <br>\n",
    "Let s = min{ A[1], ..., A[n] } and b = max { A[1], ..., A[n] }. <br>\n",
    "Let r = b - s <br>\n",
    "Prove that we can sort A in time O(n + r). <br>\n",
    "<br>\n",
    "We know that we have integers between b and s and the difference between them is r. So we can consider Bucket sort or bin sort which is a sorting algorithm that works by distributing the elements of an array into a number of buckets. Each bucket is then sorted individually, either using a different sorting algorithm, or by recursively applying the bucket sorting algorithm. But since here we have integers we should not worry about 2 or more different objects being put in the same bucket. This is how it works: <br>\n",
    "At first we have to create r+1 buckets after we have to scroll down our array for each element and assign each integer to its specific bucket so the runtime for this operation is just n, Then we have to join and combine all the buckets together so one more r+1. The total run time for this algorithm is:$O(2(r+1)+n)=O(r+n)$ <br>\n",
    "Below we also see how it works as well:\n",
    "First we create Buckets: $\\;\\;\\;\\;\\;\\;$    $Bucket[s],...,Bucket[b]$ <br>\n",
    "Then we scroll down the list from $A[1]$ to $A[n]$ and assign each ineger to a bucket and since we have max and min all the other integers will be surely included. <br>\n",
    "And then we simply combine the buckets in order of $Bucket[s]$ to $ Bucket[b]$. And we will have our final array:<br> \n",
    "$Sorted\\;array=[elements \\; in \\; Bucket[s],...,elements \\; in \\; Bucket[b]]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
